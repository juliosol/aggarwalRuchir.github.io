<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>EECS598 | Multi-Step Curiosity</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>EECS598-012</h1>
        <h3>Winter 2019 Course Project</h3>
        <p class="view"><a href="https://github.com/denncli/multi-step-curiosity-driven-learning">View the Project on GitHub</a></p>
        <ul>
          <li><a href="./EECS598_012_Final_Report.pdf">Project <strong>Paper</strong></a></li>
          <li><a href="./result_videos.html">Result <strong>Videos</strong></a></li>
          <li><a href="https://pathak22.github.io/large-scale-curiosity/">Project <strong>Motivation</strong></a></li>
        </ul>
      </header>
      <section>
        
        <h1>Multi-Step Curiosity Driven Learning</h1>
        <br>
        <h3>Ruchir Aggarwal* 
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
            Kushantha U. Attanayake*
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
            Dennis Li* </h3>
        <br><h3> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  
        Julio Soldevilla+
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
        Poorani Ravindhiran^ </h3>

        <p class="view"><small>
        * Computer Science and Engineering, University of Michigan <br>
        + Mathematics, University of Michigan <br>
        ^ Robotics, University of Michigan <br>
        </small></p>
        <hr>
          
        <p>Reinforcement learning has made great strides at exploring virtual environments, especially those of video games because of their well structured reward systems. However, it struggles in sparse reward scenarios. Curiosity driven exploration, where the agent is intrinsically motivated to explore the environment, has been proposed as a solution to this issue. Curiosity is a type of intrinsic reward function which uses prediction error as reward signal. However, current implementations of curiosity based learning only predict one time step into the future. As a result, if a catastrophic event were to happen two time steps away, the agent would be none the wiser.</p>
          
        <p>In this project,
            <ol>
                <li>We investigate the effects of generating multile step predictions into the future, and by using all predictions in our definition of curiosity.</li>
                <li>We perform experiments with different weight combinations for multiple step predictions and present results </li>
                <li></li>
            </ol>
        </p>

        <hr>
        
        <h2>Future Work</h2>
        
        
        <hr>

        <h2> Related Work </h2>    
            <p>Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, Alexei A. Efros. <a href="https://pathak22.github.io/large-scale-curiosity/">Large-Scale Study of Curiosity-Driven Learning</a>. In ICLR 2019.
            </p>

        <hr>

        <h2> Acknowledgement </h2>
        <p class="view">
          We would like to thank <em>Ruben Villegas</em> for proposing this project and helping us understand the different concepts involved. We would also like to extend our thanks to <em>Prof. Honglak Lee</em> for all his help.
        </p>
          
      </section>
      <footer>
        <p><small>A Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
